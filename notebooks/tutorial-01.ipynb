{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain QuickStart Tutorial\n",
    "\n",
    "I'm essentially following this QuickStart:\n",
    "\n",
    "https://python.langchain.com/docs/get_started/quickstart\n",
    "\n",
    "However, I've modified some of the statements and queries. I'm also using Azure OpenAI so some of the imports differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "# Use a local .env file to populate environment variables\n",
    "dotenv.load_dotenv(override=True)\n",
    "\n",
    "model_deployment = os.getenv('MODEL_DEPLOYMENT')\n",
    "embedding_deployment = os.getenv('EMBEDDING_DEPLOYMENT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first cell creates a basic chain with a system prompt, the llm, and an output parser.\n",
    "It then asks the LLM \"Who is Martin Peck?\" and prints the response.\n",
    "It should give a response similar to the following:\n",
    "\n",
    "> I'm sorry, but as a software engineer, I don't have specific information on individuals unless they are widely recognized in the field of software engineering or technology. Could you please provide more context?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as a software engineer, I don't have specific information on individuals unless they are significant in the field of technology or software development. I can't provide information about Martin Peck.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=model_deployment)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a software engineer. When responding, be brief and to the point.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"input\": \"Who is Martin Peck?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell uses the WebBaseLoader (which, under the covers, uses BeautifulSoup) to scrape my blog \"About\" page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# scrape the web page\n",
    "loader = WebBaseLoader(\"https://martinpeck.com/about/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare an embedding model (again, using the Azure OpenAI service), chunk the scraped web page, and then generate and store embeddings in a local FAISS vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# prep the embedding model\n",
    "embeddings = AzureOpenAIEmbeddings(azure_deployment=embedding_deployment)\n",
    "\n",
    "# split the scraped web page into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# create embeddings and store them in a local FAISS vector store\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set up a chat template that allows us to inject both context and a question into the chat.\n",
    "When we invoke this chain the LLM is given the context from the vector store, and this time when asked \"Who is Martin Peck\" should respond with something similar to the following:\n",
    "\n",
    "> Martin Peck is a software engineer with over 20 years of experience in writing software and leading software development teams. He is currently a Software Engineering Manager at Microsoft, where he manages a team of Software Engineers. He has also worked for blinkbox and was previously the Director of Engineering for a not-for-profit called Code Club. In addition to his work in software, he also draws and publishes cartoons, some of which can be found for sale at Redbubble and Zazzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martin Peck is a software developer and team leader with over 20 years of professional experience. He is currently a Software Engineering Manager at Microsoft, leading a team within the Commercial Software Engineering (CSE) team. He has also worked for the company blinkbox, where he served as the Head of Client Device Development and Director of Engineering. Additionally, he was the Director of Engineering for a not-for-profit called Code Club, which aims to teach children about coding and technology. In his free time, he draws and publishes cartoons.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": \"Who is Martin Peck?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Is Martin a software engineer?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'for how long?',\n",
       " 'context': [Document(page_content='About Me | martinpeck.com\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nhome\\n\\n\\nabout\\n\\n\\ncartoons\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nmartinpeck.com\\n\\n         A blog, written by someone called Martin Peck\\n    \\n\\n\\n\\n\\n\\nAbout Me\\n\\n\\nHi. I’m Martin Peck. I’ve spent the last 20+ years getting paid for writing software and leading teams of software developers. When I’m not doing that I’m generally doing whatever my family tell me to do.\\nYou can find in these other places:\\n\\nGitHub.com\\nStack Overflow\\nLinkedIn\\nTwitter\\n\\nI also draw and publish cartoons. Some of my creations can be found on sale at Redbubble and Zazzle.\\n\\nMicrosoft (again)\\nI’ve returned to Microsoft, and I’m currently a Software Engineering Manager at Microsoft, within the Commercial Software Engineering (CSE) team. I manage a team of Software Engineers who work on software projects that have real scale, and high importance, to many of Microsoft’s biggest customers. I also get to contribute to OSS software, write code in lots of languages (Python, Golang, and sometimes…C#), and I don’t have to use a Windows machine. I <3 the new Microsoft!\\nCode Club\\nI was previously the Director of Engineering for a fantastic not-for-profit called Code Club . Code Club’s mission is to help kids learn about writing code and to get them excited about technology in general. Volunteers help run after school clubs across the UK. I happen to be one of those volunteers, running a club in a local school.\\nGet involved! It’s easy, fun and incredibly rewarding. I run my own Code Club at a local school and it’s one of the highlights of my week.\\nblinkbox Movies and blinkbox Books\\nI have worked for blinkbox (previously part of Tescos) within the blinkbox Movies team and blinkbox Books team.\\nWithin blinkbox Movies I was the Head of Client Device Development. In this role I was responsible for the development of the client apps that blinkbox owned (website, mobile apps, games console and set-top boxes).\\nIn the blinkbox Books team I was Director of Engineering, and helped build an engineering team and launch a brand new eBook service.\\nSadly, Tesco sold blinkbox at the start of 2015. blinkbox was full of excellent people, and I loved working there.\\nMicrosoft\\nI worked for Microsoft, in the UK, for just over 10 years. During that time I worked on a number of projects, but for the last 5 of those years I worked within Microsoft Mediaroom. I headed up a remote dev team in the UK that was part of the San Francisco based product group.\\nWe shipped an IPTV platform that’s used around the world by many Telecoms companies.\\nHealth Warning about Everything on this Site\\nNothing you read on this blog, or anything that I write on social media, is written on behalf of the organisations I have previously or currently work for. None of what you read should be considered an expression of their views, or endorsed by them.\\nAt times, some of it won’t even be stuff that I agree with.\\nAcknowledgements\\nThis blog is using a modified version of Mediumish, which is an excellent Jekyll theme. I’m using Jekyll to build the blog, and hosting on Github.com. Feel free to take a look.\\n\\n\\n\\n\\n\\n\\n\\n\\n                 Copyright © 2023 Martin Peck\\n            \\n\\n                theme based upon Mediumish', metadata={'source': 'https://martinpeck.com/about/', 'title': 'About Me | martinpeck.com', 'language': 'en'})],\n",
       " 'answer': 'Martin Peck has been getting paid for writing software and leading teams of software developers for over 20 years.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Is Martin a software engineer?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"for how long?\"\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
